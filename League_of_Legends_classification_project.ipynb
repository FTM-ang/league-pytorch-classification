{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# League of Legends Match Outcome Prediction\n",
        "\n",
        "This project predicts whether a League of Legends match is won or lost using a logistic regression model implemented in PyTorch. The notebook includes exploratory data analysis (EDA), data preprocessing, model training, evaluation, and visualization.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Import Libraries\n"
      ],
      "metadata": {
        "id": "hnWtD0FoLRrY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxxGew6qLJfO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset\n",
        "Load the dataset and inspect the first few rows and basic info.\n"
      ],
      "metadata": {
        "id": "DMKMBdrjLZbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('league_of_legends_data_large.csv')\n",
        "print(\"Dataset Shape:\", data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "v4yy63s_LXEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "We will check:\n",
        "\n",
        "- Target distribution\n",
        "- Some basic statistics of features\n",
        "- Correlation heatmap\n",
        "\n"
      ],
      "metadata": {
        "id": "9FeqFHdlLggk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target distribution\n",
        "sns.countplot(x='win', data=data)\n",
        "plt.title(\"Win/Loss Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(data.describe())\n",
        "\n",
        "# Correlation heatmap (for top 10 features with highest variance)\n",
        "top_features = data.var().sort_values(ascending=False).head(10).index\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(data[top_features].corr(), cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap of Top Features\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k8O3DuKdLlW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Preprocessing\n",
        "Split the data, standardize features, and convert to PyTorch tensors.\n"
      ],
      "metadata": {
        "id": "LbxDnkStLn8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('win', axis=1)\n",
        "y = data['win']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.FloatTensor(y_train.values).view(-1, 1)\n",
        "y_test = torch.FloatTensor(y_test.values).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "QBkWjC6ALp6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define Logistic Regression Model in PyTorch\n"
      ],
      "metadata": {
        "id": "_5gzy1VjLtD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "input_dimention = X_train.shape[1]\n",
        "model = LogisticRegressionModel(input_dimention, output_size=1)\n"
      ],
      "metadata": {
        "id": "_oGcJdBaLsuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train the Model\n",
        "We use binary cross-entropy loss and SGD optimizer with L2 regularization (weight decay).\n"
      ],
      "metadata": {
        "id": "C1C8c8zjLyBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loss_function = nn.BCELoss()\n",
        "optimizer_regularised = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "\n",
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "    model.train()\n",
        "    optimizer_regularised.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = Loss_function(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer_regularised.step()\n"
      ],
      "metadata": {
        "id": "flOE0opSLyqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluate the Model\n"
      ],
      "metadata": {
        "id": "U8iJ5t73L0xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_probs = model(X_test)\n",
        "    y_pred = (y_pred_probs > 0.5).int()\n",
        "\n",
        "y_test_np = y_test.cpu().numpy()\n",
        "y_pred_np = y_pred.cpu().numpy()\n",
        "y_pred_probs_np = y_pred_probs.cpu().numpy()\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_np, y_pred_np)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_np, y_pred_np, digits=4))\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test_np, y_pred_probs_np)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "print(f\"AUC Score: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "6WrbyGQoL2is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Feature Importance Analysis\n",
        "\n",
        "In logistic regression, the weights of the linear layer indicate the impact of each feature on the prediction.  \n",
        "Larger absolute weights correspond to more influential features. Positive weights suggest a positive correlation with the outcome (predicting the positive class), while negative weights suggest the opposite.  \n",
        "\n",
        "This section extracts the model weights, creates a DataFrame to display feature importance, and visualizes the top 15 features.\n"
      ],
      "metadata": {
        "id": "OnwoxtX-MuFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Extract model weights\n",
        "#model.linear.weight shape: [1, num_features], flatten to 1D array\n",
        "feature_weights = model.linear.weight.data.numpy().flatten()\n",
        "\n",
        "\n",
        "feature_names = data.drop('win', axis=1).columns\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_weights\n",
        "})\n",
        "\n",
        "#Sort by absolute value of importance\n",
        "feature_importance_df['Abs_Importance'] = np.abs(feature_importance_df['Importance'])\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Abs_Importance', ascending=False)\n",
        "\n",
        "\n",
        "print(\"Top 15 Features by Importance:\\n\")\n",
        "print(feature_importance_df.head(15))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.barh(feature_importance_df['Feature'][:15][::-1], feature_importance_df['Importance'][:15][::-1])\n",
        "plt.xlabel('Importance (Weight Value)')\n",
        "plt.title('Top 15 Feature Importances')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0CS5IAq_MvHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "- The logistic regression model using PyTorch successfully predicts match outcomes.\n",
        "- EDA provided insights into feature correlations and target distribution.\n",
        "- Confusion matrix, classification report, and ROC/AUC curves give a clear understanding of model performance.\n",
        "- This notebook can be uploaded to GitHub as a portfolio-ready project.\n"
      ],
      "metadata": {
        "id": "P2vh7sFBL4ad"
      }
    }
  ]
}